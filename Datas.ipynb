{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification using BFGS -- Pytorch version\n",
        "\n",
        "This notebook details the implementation of a generic ridge-regularized classification solved by direct gradient-based optimization (here quasi-newton). \n",
        "It is implemented in the kernel space, i.e. representing the weights over the space of points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ij0BFq1STLcv"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/gguichaoua/Dropbox/gwenn/these/TNBC/chemogenomic-git/Datas.ipynb Cellule 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gguichaoua/Dropbox/gwenn/these/TNBC/chemogenomic-git/Datas.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gguichaoua/Dropbox/gwenn/these/TNBC/chemogenomic-git/Datas.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gguichaoua/Dropbox/gwenn/these/TNBC/chemogenomic-git/Datas.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gguichaoua/Dropbox/gwenn/these/TNBC/chemogenomic-git/Datas.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gguichaoua/Dropbox/gwenn/these/TNBC/chemogenomic-git/Datas.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device_cpu = torch.device(\"cpu\")\n",
        "device_cpu = device\n",
        "print( device )\n",
        "\n",
        "mytype = torch.float16 # to save memory (only on GPU)\n",
        "mytype = torch.float32"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I_pKDD-zj7Fa"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kprot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('data/CC_all2_base_K_prot.data', 'rb') as f:\n",
        "        K_prot = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1647, 1647)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K_prot.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## liste des 152 844 smiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "152844"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# same in zip format\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "zf = zipfile.ZipFile('data/Consensus_CompoundBioactivity_Dataset_v1.1_Sh2_all2.csv.zip') \n",
        "df = pd.read_csv(zf.open('Consensus_CompoundBioactivity_Dataset_v1.1_Sh2_all2.csv'),low_memory=False)\n",
        "df_p = df[df['interaction+'] == True]\n",
        "#list of smiles strings\n",
        "smiles = df_p['standardized smiles'].drop_duplicates().values\n",
        "len(smiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "nM = 10000 # len(smiles)\n",
        "MorganFP = np.zeros((nM,1024))\n",
        "for i in range(nM):\n",
        "    # Convert SMILES to RDKit molecule object\n",
        "    mol = Chem.MolFromSmiles(smiles[i])    \n",
        "    # Generate Morgan fingerprint of the molecule\n",
        "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)\n",
        "    # Convert the fingerprint to a numpy array\n",
        "    arr = np.zeros((1,))\n",
        "    AllChem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "    MorganFP[i,:] = arr\n",
        "MorganFP = MorganFP.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import Nystrom_method\n",
        "from  Nystrom_method import nystroem,KronKernel\n",
        "# random list of molecules \n",
        "kM = 3000 # number of molecule to compute nystrom\n",
        "rM = 1000 # final dimension of features\n",
        "I = np.random.permutation(nM)\n",
        "I = I[:kM]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute Tanimoto kernel \n",
        "Km = ( MorganFP[I,:] @ MorganFP.T ) / ( 1024 - (1-MorganFP[I,:]) @ (1-MorganFP.T) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xm,Lambda,LambdaC = nystroem(np.concatenate((Km[:,I], Km), axis=1),rM)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## liste des indices protéines/molécules avec que des 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "231964\n",
            "231964\n"
          ]
        }
      ],
      "source": [
        "# protein indices\n",
        "J = df_p['indfasta'].values\n",
        "print(len(J))\n",
        "# molecules indices\n",
        "I = df_p['indsmiles'].values\n",
        "print(len(I))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## train/test avec indices protéines/molécules et interactions balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "371142\n"
          ]
        }
      ],
      "source": [
        "# load with pickle\n",
        "import pickle\n",
        "with open('data/train.data', 'rb') as f:\n",
        "        train = pickle.load(f)\n",
        "with open('data/test.data', 'rb') as f:\n",
        "        test = pickle.load(f)\n",
        "\n",
        "print(len(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   145, 124184,      1],\n",
              "       [   145, 125039,      1],\n",
              "       [   145,  48320,      1],\n",
              "       ...,\n",
              "       [  1643, 150939,      0],\n",
              "       [  1647, 152928,      1],\n",
              "       [  1647, 126691,      0]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en premier l'indice de la protéine, puis l'indice du ligand puis l'interaction\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train (366418, 3)\n",
            "test (91606, 3)\n",
            "train (366418, 3)\n",
            "test (91606, 3)\n",
            "train (366420, 3)\n",
            "test (91604, 3)\n",
            "train (366420, 3)\n",
            "test (91604, 3)\n",
            "train (366420, 3)\n",
            "test (91604, 3)\n",
            "Train/test datasets prepared.\n"
          ]
        }
      ],
      "source": [
        "from utils import make_train_test\n",
        "all_train_interactions_arr, all_test_interactions_arr = make_train_test(df,5,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('data/CC_train_arr.data', 'wb') as f:\n",
        "    pickle.dump(all_train_interactions_arr, f)\n",
        "with open('data/CC_test_arr.data', 'wb') as f:\n",
        "    pickle.dump(all_test_interactions_arr, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
